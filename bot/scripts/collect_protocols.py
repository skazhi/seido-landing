"""
Seido - –°–±–æ—Ä –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∑–∞–±–µ–≥–æ–≤
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ —Å —Å–∞–π—Ç–æ–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤.
–°–ø–∏—Å–æ–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤: docs/ORGANIZERS.md
"""
import asyncio
import aiohttp
import aiofiles
from pathlib import Path
from datetime import datetime, timedelta, date
import re
from bs4 import BeautifulSoup

PROTOCOLS_DIR = Path(__file__).parent.parent / "protocols"
PROTOCOLS_DIR.mkdir(exist_ok=True)

# –§–∏–ª—å—Ç—Ä –≥–æ–¥–∞ –¥–ª—è —Å–±–æ—Ä–∞ (2026 ‚Äî —Ç–µ–∫—É—â–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
RESULTS_YEAR = 2026


def _safe_filename(name: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
    return re.sub(r'[^\w\s\-\.]', '_', name)[:200]


async def download_file(url: str, filepath: Path):
    """–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –ø–æ URL"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    async with aiofiles.open(filepath, 'wb') as f:
                        async for chunk in response.content.iter_chunked(8192):
                            await f.write(chunk)
                    return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url}: {e}")
    return False


async def find_5verst_protocols():
    """–ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –Ω–∞ 5verst.ru"""
    print("üîç –ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –Ω–∞ 5verst.ru...")
    
    base_url = "https://5verst.ru"
    protocols = []
    
    try:
        async with aiohttp.ClientSession() as session:
            # –ò—â–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            async with session.get(f"{base_url}/results") as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã (PDF, Excel)
                    links = soup.find_all('a', href=re.compile(r'\.(pdf|xlsx|xls)$', re.I))
                    for link in links[:10]:  # –ü–µ—Ä–≤—ã–µ 10
                        url = link.get('href')
                        if not url.startswith('http'):
                            url = f"{base_url}{url}"
                        protocols.append({
                            'url': url,
                            'name': link.text.strip() or url.split('/')[-1],
                            'source': '5verst'
                        })
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ 5verst: {e}")
    
    return protocols


async def find_rhr_protocols():
    """–ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –Ω–∞ rhr-marathon.ru"""
    print("üîç –ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –Ω–∞ rhr-marathon.ru...")
    
    base_url = "https://rhr-marathon.ru"
    protocols = []
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{base_url}/results") as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    links = soup.find_all('a', href=re.compile(r'\.(pdf|xlsx|xls)$', re.I))
                    for link in links[:20]:
                        url = link.get('href')
                        if not url.startswith('http'):
                            url = base_url + (url if url.startswith('/') else '/' + url)
                        name = link.text.strip() or url.split('/')[-1]
                        if str(RESULTS_YEAR) in name or str(RESULTS_YEAR) in url:
                            protocols.append({
                                'url': url,
                                'name': name,
                                'source': 'RHR',
                                'year': RESULTS_YEAR
                            })
                    if not protocols and links:
                        for link in links[:20]:
                            url = link.get('href')
                            if not url.startswith('http'):
                                url = base_url + (url if url.startswith('/') else '/' + url)
                            protocols.append({
                                'url': url,
                                'name': (link.text.strip() or url.split('/')[-1]),
                                'source': 'RHR'
                            })
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ RHR: {e}")
    
    return protocols


async def find_s95_protocols():
    """–ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ s95.ru"""
    print("üîç –ü–æ–∏—Å–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ s95.ru...")
    
    base_url = "https://s95.ru"
    protocols = []
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{base_url}/activities") as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    links = soup.find_all('a', href=re.compile(r'\.(pdf|xlsx|xls)$', re.I))
                    for link in links[:15]:
                        url = link.get('href')
                        if not url.startswith('http'):
                            url = base_url + (url if url.startswith('/') else '/' + url)
                        protocols.append({
                            'url': url,
                            'name': (link.text.strip() or url.split('/')[-1]),
                            'source': 'S95'
                        })
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ S95: {e}")
    
    return protocols


async def find_russiarunning_protocols():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–±–µ–≥–æ–≤ RussiaRunning –∑–∞ 2026 —á–µ—Ä–µ–∑ API.
    –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —Å–æ–±—ã—Ç–∏–π.
    """
    print("üîç –ü–æ–∏—Å–∫ –∑–∞–±–µ–≥–æ–≤ RussiaRunning (2026)...")
    
    api_url = "https://russiarunning.com/api/events/list/ru"
    events = []
    
    try:
        payload = {
            "Take": 500,
            "DateFrom": f"{RESULTS_YEAR}-01-01",
            "DateTo": f"{RESULTS_YEAR}-12-31"
        }
        headers = {"Content-Type": "application/json", "User-Agent": "Mozilla/5.0"}
        
        async with aiohttp.ClientSession() as session:
            async with session.post(api_url, json=payload, headers=headers) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    for item in data.get("Items", []):
                        event_date = item.get("d", "").split("T")[0]
                        if str(RESULTS_YEAR) in event_date:
                            event_id = item.get("c", "")
                            events.append({
                                'url': f"https://russiarunning.com/event/{event_id}/",
                                'name': f"russiarunning_{item.get('t', 'event')}_{event_date}",
                                'source': 'RussiaRunning',
                                'event_id': event_id,
                                'event_date': event_date
                            })
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π 2026: {len(events)}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ RussiaRunning API: {e}")
    
    return events


async def collect_protocols(year: int = None):
    """
    –°–æ–±—Ä–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª—ã —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    year: —Ñ–∏–ª—å—Ç—Ä –≥–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é RESULTS_YEAR=2026)
    """
    year = year or RESULTS_YEAR
    print("=" * 60)
    print(f"üì• –°–ë–û–† –ü–†–û–¢–û–ö–û–õ–û–í –ó–ê–ë–ï–ì–û–í (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç {year})")
    print("=" * 60)
    
    all_protocols = []
    
    # –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä—ã –∏–∑ docs/ORGANIZERS.md
    all_protocols.extend(await find_5verst_protocols())
    all_protocols.extend(await find_rhr_protocols())
    all_protocols.extend(await find_s95_protocols())
    
    # RussiaRunning ‚Äî —Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π 2026 (–¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Å–±–æ—Ä–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)
    rr_events = await find_russiarunning_protocols()
    all_protocols.extend(rr_events)
    
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/—Å–æ–±—ã—Ç–∏–π: {len(all_protocols)}")
    
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã (PDF, Excel)
    downloaded = 0
    event_urls = {}  # source -> [(name, url), ...]
    
    for proto in all_protocols:
        url = proto['url']
        name = proto.get('name', '') or url.split('/')[-1].split('?')[0]
        
        if re.search(r'\.(pdf|xlsx|xls)$', url, re.I):
            if not name.endswith(('.pdf', '.xlsx', '.xls')):
                name = name + ('.pdf' if '.pdf' in url.lower() else '.xlsx')
            filepath = PROTOCOLS_DIR / _safe_filename(name)
            if filepath.exists():
                print(f"‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω (—É–∂–µ –µ—Å—Ç—å): {name}")
                continue
            print(f"‚¨á –°–∫–∞—á–∏–≤–∞—é: {name}...")
            if await download_file(url, filepath):
                print(f"‚úÖ –°–∫–∞—á–∞–Ω: {name}")
                downloaded += 1
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {name}")
        else:
            # URL –±–µ–∑ —Ñ–∞–π–ª–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–±—ã—Ç–∏—è) ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            src = proto.get('source', 'other')
            event_urls.setdefault(src, []).append((name, url))
    
    for src, items in event_urls.items():
        list_file = PROTOCOLS_DIR / f"urls_{src}_{year}.txt"
        with open(list_file, 'w', encoding='utf-8') as f:
            for n, u in items:
                f.write(f"{n}\t{u}\n")
        print(f"üìã –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(items)} —Å—Å—ã–ª–æ–∫: {list_file.name}")
    
    print(f"\n‚úÖ –°–∫–∞—á–∞–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {downloaded}")
    print(f"üìÅ –ü–∞–ø–∫–∞: {PROTOCOLS_DIR}")
    
    return downloaded


async def main():
    await collect_protocols()


if __name__ == "__main__":
    asyncio.run(main())
